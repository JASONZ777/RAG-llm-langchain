# Demo 1ï¼š
Just run main.py

Embedding model: OpenAI

Generation model: gpt-3.5-turbo

<img width="1151" alt="ee52a6d70f3fe37087baed2c56943b4" src="https://github.com/JASONZ777/RAG-llm-langchain-interface/assets/94668646/9b7ef93c-e96c-4d51-9819-6be3a5940220">

# Demo 2:
In Demo 2, we add memory history to support multiple-round chatting.

Embedding model: OpenAI
Generation model: llama2-7b-chat, quantized to 4bits

